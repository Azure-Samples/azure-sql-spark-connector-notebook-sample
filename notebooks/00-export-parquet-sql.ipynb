{"cells":[{"cell_type":"code","source":["def mountFileSystem(containerName, storageAccountName):\n  configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n       \"fs.azure.account.oauth2.client.id\": dbutils.secrets.get(scope = \"kvbenchmark\", key = \"sp-adls-appid\"),\n       \"fs.azure.account.oauth2.client.secret\": dbutils.secrets.get(scope = \"kvbenchmark\", key = \"sp-adls-secret\"),\n       \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/microsoft.onmicrosoft.com/oauth2/token\",\n       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n  \n  mountPoint = \"/mnt/adls/\" + storageAccountName + \"/\" + containerName\n  try:\n    dbutils.fs.mount(\n      source = \"abfss://\" + containerName + \"@\" + storageAccountName + \".dfs.core.windows.net\",\n      mount_point = mountPoint,\n      extra_configs = configs\n    )\n    print(mountPoint + \" mounted successfully\")\n  except:\n    print(\"The mount \" + mountPoint + \" already exists.\")\n\n  return mountPoint\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["mountFileSystem(\"tpcds1tb\", \"adls7dataset7benchmark\")"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["import os\nparquet_path = \"/mnt/adls/adls7dataset7benchmark/tpcds1tb/parquet/\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["server_name = dbutils.secrets.get(scope = \"kvbenchmark\", key = \"db-server-url\")\ndatabase_name = dbutils.secrets.get(scope = \"kvbenchmark\", key = \"db-name-noidx\")\nurl = server_name + \";\" + \"databaseName=\" + database_name + \";\"\n\nusername = dbutils.secrets.get(scope = \"kvbenchmark\", key = \"db-username\")\npassword = dbutils.secrets.get(scope = \"kvbenchmark\", key = \"db-password\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["table_name = \"dbo.store\"\ndf = spark.read \\\n        .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n        .option(\"url\", url) \\\n        .option(\"dbtable\", table_name) \\\n        .option(\"user\", username) \\\n        .option(\"password\", password) \\\n        .load()\n\ndf.write.parquet(os.path.join(parquet_path, \"store\"), mode=\"overwrite\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["table_name = \"dbo.store_sales\"\ndf = spark.read \\\n        .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n        .option(\"url\", url) \\\n        .option(\"dbtable\", table_name) \\\n        .option(\"user\", username) \\\n        .option(\"password\", password).load()\n\ndf.write.parquet(os.path.join(parquet_path, \"store_sales\"), mode=\"overwrite\", partitionBy=\"ss_store_sk\")"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["table_name = \"dbo.store_returns\"\ndf = spark.read \\\n        .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n        .option(\"url\", url) \\\n        .option(\"dbtable\", table_name) \\\n        .option(\"user\", username) \\\n        .option(\"password\", password).load()\n\ndf.write.parquet(os.path.join(parquet_path, \"store_returns\"), mode=\"overwrite\", partitionBy=\"sr_store_sk\")"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["table_name = \"dbo.customer\"\ndf = spark.read \\\n        .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n        .option(\"url\", url) \\\n        .option(\"dbtable\", table_name) \\\n        .option(\"user\", username) \\\n        .option(\"password\", password).load()\n\ndf.write.parquet(os.path.join(parquet_path, \"customer\"), mode=\"overwrite\")"],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"export-parquet-sql","notebookId":2494167886316448},"nbformat":4,"nbformat_minor":0}
